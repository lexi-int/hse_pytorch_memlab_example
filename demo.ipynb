{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch_memlab\n",
    "**A library for memory profiling. Uses torch.cuda.memory_stats() inside.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.6.0 in /home/lexi/.venv/lib/python3.6/site-packages (1.6.0)\n",
      "Requirement already satisfied: transformers==3.2.0 in /home/lexi/.venv/lib/python3.6/site-packages (3.2.0)\n",
      "Requirement already satisfied: pytorch-memlab==0.2.4 in /home/lexi/.venv/lib/python3.6/site-packages (0.2.4)\n",
      "Requirement already satisfied: future in /home/lexi/.venv/lib/python3.6/site-packages (from torch==1.6.0) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/lexi/.venv/lib/python3.6/site-packages (from torch==1.6.0) (1.18.1)\n",
      "Requirement already satisfied: requests in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (2.22.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (0.8)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (0.1.96)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (2022.1.18)\n",
      "Requirement already satisfied: packaging in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (0.8.1rc2)\n",
      "Requirement already satisfied: filelock in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (3.4.1)\n",
      "Requirement already satisfied: sacremoses in /home/lexi/.venv/lib/python3.6/site-packages (from transformers==3.2.0) (0.0.47)\n",
      "Requirement already satisfied: setuptools in /home/lexi/.venv/lib/python3.6/site-packages (from pytorch-memlab==0.2.4) (42.0.2)\n",
      "Requirement already satisfied: pandas>=0.18 in /home/lexi/.venv/lib/python3.6/site-packages (from pytorch-memlab==0.2.4) (0.25.3)\n",
      "Requirement already satisfied: calmsize in /home/lexi/.venv/lib/python3.6/site-packages (from pytorch-memlab==0.2.4) (0.1.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/lexi/.venv/lib/python3.6/site-packages (from requests->transformers==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lexi/.venv/lib/python3.6/site-packages (from requests->transformers==3.2.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/lexi/.venv/lib/python3.6/site-packages (from requests->transformers==3.2.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/lexi/.venv/lib/python3.6/site-packages (from requests->transformers==3.2.0) (1.25.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/lexi/.venv/lib/python3.6/site-packages (from packaging->transformers==3.2.0) (2.4.6)\n",
      "Requirement already satisfied: joblib in /home/lexi/.venv/lib/python3.6/site-packages (from sacremoses->transformers==3.2.0) (0.14.1)\n",
      "Requirement already satisfied: click in /home/lexi/.venv/lib/python3.6/site-packages (from sacremoses->transformers==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: six in /home/lexi/.venv/lib/python3.6/site-packages (from sacremoses->transformers==3.2.0) (1.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/lexi/.venv/lib/python3.6/site-packages (from pandas>=0.18->pytorch-memlab==0.2.4) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/lexi/.venv/lib/python3.6/site-packages (from pandas>=0.18->pytorch-memlab==0.2.4) (2019.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/lexi/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.6.0 transformers==3.2.0 pytorch-memlab==0.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_memlab import LineProfiler, MemReporter, profile\n",
    "from transformers import BertForTokenClassification, BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "                'bert-base-cased',\n",
    "                num_labels=10\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Reporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the memory used by the model tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element type                                            Size  Used MEM\n",
      "-------------------------------------------------------------------------------\n",
      "Storage on cuda:0\n",
      "Tensor207                                           (1, 512)     4.00K\n",
      "bert.embeddings.word_embeddings.weight          (28996, 768)    84.95M\n",
      "bert.embeddings.position_embeddings.weight          (512, 768)     1.50M\n",
      "bert.embeddings.token_type_embeddings.weight            (2, 768)     6.00K\n",
      "bert.embeddings.LayerNorm.weight                      (768,)     3.00K\n",
      "bert.embeddings.LayerNorm.bias                        (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.0.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.0.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.0.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.0.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.0.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.1.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.1.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.1.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.1.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.1.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.2.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.2.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.2.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.2.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.2.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.3.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.3.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.3.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.3.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.3.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.4.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.4.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.4.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.4.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.4.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.5.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.5.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.5.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.5.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.5.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.6.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.6.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.6.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.6.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.6.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.7.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.7.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.7.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.7.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.7.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.8.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.8.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.8.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.8.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.8.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.9.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.9.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.9.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.9.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.9.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.10.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.10.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.10.output.dense.bias               (768,)     3.00K\n",
      "bert.encoder.layer.10.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.10.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.11.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.11.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.11.output.dense.bias               (768,)     3.00K\n",
      "bert.encoder.layer.11.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.11.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.pooler.dense.weight                          (768, 768)     2.25M\n",
      "bert.pooler.dense.bias                                (768,)     3.00K\n",
      "classifier.weight                                  (10, 768)    30.00K\n",
      "classifier.bias                                        (10,)   512.00B\n",
      "-------------------------------------------------------------------------------\n",
      "Total Tensors: 108318474 \tUsed Memory: 413.20M\n",
      "The allocated memory on cuda:0: 413.70M\n",
      "Memory differs due to the matrix alignment or invisible gradient buffer tensors\n",
      "-------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lexi/.venv/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:125: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "reporter = MemReporter(model)\n",
    "reporter.report(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer(['This is a sentence'], return_tensors='pt').to(device)\n",
    "labels = torch.Tensor([1] * len(data.input_ids[0])).to(dtype=torch.long).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, logits = model(data.input_ids, token_type_ids=None, attention_mask=data.attention_mask, labels=labels)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculated the gradients and they are now shown in memory inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element type                                            Size  Used MEM\n",
      "-------------------------------------------------------------------------------\n",
      "Storage on cuda:0\n",
      "bert.embeddings.word_embeddings.weight          (28996, 768)    84.95M\n",
      "bert.embeddings.word_embeddings.weight.grad        (28996, 768)    84.95M\n",
      "bert.embeddings.position_embeddings.weight          (512, 768)     1.50M\n",
      "bert.embeddings.position_embeddings.weight.grad          (512, 768)     1.50M\n",
      "bert.embeddings.token_type_embeddings.weight            (2, 768)     6.00K\n",
      "bert.embeddings.token_type_embeddings.weight.grad            (2, 768)     6.00K\n",
      "bert.embeddings.LayerNorm.weight                      (768,)     3.00K\n",
      "bert.embeddings.LayerNorm.weight.grad                 (768,)     3.00K\n",
      "bert.embeddings.LayerNorm.bias                        (768,)     3.00K\n",
      "bert.embeddings.LayerNorm.bias.grad                   (768,)     3.00K\n",
      "bert.pooler.dense.weight                          (768, 768)     2.25M\n",
      "bert.pooler.dense.bias                                (768,)     3.00K\n",
      "classifier.weight                                  (10, 768)    30.00K\n",
      "classifier.weight.grad                             (10, 768)    30.00K\n",
      "classifier.bias                                        (10,)   512.00B\n",
      "classifier.bias.grad                                   (10,)   512.00B\n",
      "Tensor0                                             (1, 512)     4.00K\n",
      "Tensor1                                               (1, 6)   512.00B\n",
      "Tensor2                                               (1, 6)   512.00B\n",
      "Tensor3                                                 (6,)   512.00B\n",
      "Tensor4                                           (1, 6, 10)   512.00B\n",
      "Tensor5                                                 (1,)   512.00B\n",
      "Tensor6                                               (1, 6)   512.00B\n",
      "bert.encoder.layer.10.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.0.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.0.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.0.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.0.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.0.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.0.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.0.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.0.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.0.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.0.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.1.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.1.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.1.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.1.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.1.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.1.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.1.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.1.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.1.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.1.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.1.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.2.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.2.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.2.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.2.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.2.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.2.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.2.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.2.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.2.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.2.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.2.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.3.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.3.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.3.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.3.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.3.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.3.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.3.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.3.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.3.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.3.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.3.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.4.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.4.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.4.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.4.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.4.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.4.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.4.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.4.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.4.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.4.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.4.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.5.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.5.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.5.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.5.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.5.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.5.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.5.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.5.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.5.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.5.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.5.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.6.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.6.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.6.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.6.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.6.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.6.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.6.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.6.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.6.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.6.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.6.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.7.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.7.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.7.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.7.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.7.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.7.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.7.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.7.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.7.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.7.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.7.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.8.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.8.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.8.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.8.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.8.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.8.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.8.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.8.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.8.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.8.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.8.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.9.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.9.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.9.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.9.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.9.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.9.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.9.output.dense.bias                (768,)     3.00K\n",
      "bert.encoder.layer.9.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.9.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.9.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.9.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.10.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.10.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.10.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.10.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.10.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.10.output.dense.bias               (768,)     3.00K\n",
      "bert.encoder.layer.10.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.10.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.10.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.intermediate.dense.weight         (3072, 768)     9.00M\n",
      "bert.encoder.layer.11.intermediate.dense.weight.grad         (3072, 768)     9.00M\n",
      "bert.encoder.layer.11.intermediate.dense.bias             (3072,)    12.00K\n",
      "bert.encoder.layer.11.intermediate.dense.bias.grad             (3072,)    12.00K\n",
      "bert.encoder.layer.11.output.dense.weight         (768, 3072)     9.00M\n",
      "bert.encoder.layer.11.output.dense.weight.grad         (768, 3072)     9.00M\n",
      "bert.encoder.layer.11.output.dense.bias               (768,)     3.00K\n",
      "bert.encoder.layer.11.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.11.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.query.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.query.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.query.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.query.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.key.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.key.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.key.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.key.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.value.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.value.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.self.value.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.self.value.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.dense.weight          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.output.dense.weight.grad          (768, 768)     2.25M\n",
      "bert.encoder.layer.11.attention.output.dense.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.dense.bias.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight.grad              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias              (768,)     3.00K\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias.grad              (768,)     3.00K\n",
      "-------------------------------------------------------------------------------\n",
      "Total Tensors: 216045929 \tUsed Memory: 824.16M\n",
      "The allocated memory on cuda:0: 825.16M\n",
      "Memory differs due to the matrix alignment or invisible gradient buffer tensors\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "reporter = MemReporter(model)\n",
    "reporter.report(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see that some variables are shared: reused memory is shown by '->'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_memlab import LineProfiler, MemReporter\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element type                                            Size  Used MEM\n",
      "-------------------------------------------------------------------------------\n",
      "Storage on cuda:0\n",
      "weight_ih_l0                                    (4096, 1024)    32.03M\n",
      "weight_hh_l0(->weight_ih_l0)                    (4096, 1024)     0.00B\n",
      "bias_ih_l0(->weight_ih_l0)                           (4096,)     0.00B\n",
      "bias_hh_l0(->weight_ih_l0)                           (4096,)     0.00B\n",
      "-------------------------------------------------------------------------------\n",
      "Total Tensors: 8396800 \tUsed Memory: 32.03M\n",
      "The allocated memory on cuda:0: 32.03M\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# use verbose=True to see reused memory\n",
    "lstm = torch.nn.LSTM(1024, 1024).cuda()\n",
    "reporter = MemReporter(lstm)\n",
    "reporter.report(device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaking memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes used memory and allocated memory are not equal. This is due to memory leaks, the fact of which you can see but unfortunately not inspect. In the example below *input_tensor + 2* is a temporary operation result which is stored but not shown in memory inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Actually, if you try to run this notebook on torch==1.10.2 + transformers==4.17.0 + pytorch-memlab==0.2.4, memory leakage is gone - you'll see Tensor2 to account for a temporary result.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element type                                            Size  Used MEM\n",
      "-------------------------------------------------------------------------------\n",
      "Storage on cuda:0\n",
      "weight                                          (1024, 1024)     4.00M\n",
      "bias                                                 (1024,)     4.00K\n",
      "Tensor0                                          (512, 1024)     2.00M\n",
      "-------------------------------------------------------------------------------\n",
      "Total Tensors: 1573888 \tUsed Memory: 6.00M\n",
      "The allocated memory on cuda:0: 6.00M\n",
      "-------------------------------------------------------------------------------\n",
      "Element type                                            Size  Used MEM\n",
      "-------------------------------------------------------------------------------\n",
      "Storage on cuda:0\n",
      "weight                                          (1024, 1024)     4.00M\n",
      "bias                                                 (1024,)     4.00K\n",
      "Tensor0                                          (512, 1024)     2.00M\n",
      "Tensor1                                                 (1,)   512.00B\n",
      "-------------------------------------------------------------------------------\n",
      "Total Tensors: 1573889 \tUsed Memory: 6.00M\n",
      "The allocated memory on cuda:0: 8.00M\n",
      "Memory differs due to the matrix alignment or invisible gradient buffer tensors\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_memlab import LineProfiler, MemReporter\n",
    "\n",
    "linear = torch.nn.Linear(1024, 1024).cuda()\n",
    "input_tensor = torch.Tensor(512, 1024).cuda()\n",
    "reporter = MemReporter(linear)\n",
    "reporter.report()\n",
    "\n",
    "out = linear(input_tensor * (input_tensor + 2)).mean()\n",
    "reporter.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line profiler can show memory usage line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_memlab import LineProfiler, MemReporter, profile\n",
    "from transformers import BertForTokenClassification, BertTokenizerFast, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3><span style=\"font-family: monospace\">outer</span></h3><div><style  type=\"text/css\" >\n",
       "    #T_ded1de4a_ad03_11ec_840a_645d86784bd2 th {\n",
       "          text-align: left;\n",
       "    }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row0_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row0_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 33.0%, transparent 33.0%);\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row1_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 99.0%, transparent 99.0%);\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row1_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row2_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 66.0%, transparent 66.0%);\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row2_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 99.0%, transparent 99.0%);\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row2_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row3_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 99.0%, transparent 99.0%);\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row3_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 99.0%, transparent 99.0%);\n",
       "        }    #T_ded1de4a_ad03_11ec_840a_645d86784bd2row3_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }</style><table id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >active_bytes</th>        <th class=\"col_heading level0 col1\" >reserved_bytes</th>        <th class=\"col_heading level0 col2\" >line</th>        <th class=\"col_heading level0 col3\" >code</th>    </tr>    <tr>        <th class=\"col_heading level1 col0\" >all</th>        <th class=\"col_heading level1 col1\" >all</th>        <th class=\"col_heading level1 col2\" ></th>        <th class=\"col_heading level1 col3\" ></th>    </tr>    <tr>        <th class=\"col_heading level2 col0\" >peak</th>        <th class=\"col_heading level2 col1\" >peak</th>        <th class=\"col_heading level2 col2\" ></th>        <th class=\"col_heading level2 col3\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row0_col0\" class=\"data row0 col0\" >0.00B</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row0_col1\" class=\"data row0 col1\" >0.00B</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row0_col2\" class=\"data row0 col2\" >4</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row0_col3\" class=\"data row0 col3\" >def outer():\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row1_col0\" class=\"data row1 col0\" >40.00K</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row1_col1\" class=\"data row1 col1\" >2.00M</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row1_col2\" class=\"data row1 col2\" >5</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row1_col3\" class=\"data row1 col3\" >    linear = torch.nn.Linear(100, 100).cuda()\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row2_col0\" class=\"data row2 col0\" >80.00K</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row2_col1\" class=\"data row2 col1\" >2.00M</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row2_col2\" class=\"data row2 col2\" >6</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row2_col3\" class=\"data row2 col3\" >    linear2 = torch.nn.Linear(100, 100).cuda()\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row3_col0\" class=\"data row3 col0\" >120.00K</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row3_col1\" class=\"data row3 col1\" >2.00M</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row3_col2\" class=\"data row3 col2\" >7</td>\n",
       "                        <td id=\"T_ded1de4a_ad03_11ec_840a_645d86784bd2row3_col3\" class=\"data row3 col3\" >    inner()\n",
       "</td>\n",
       "            </tr>\n",
       "    </tbody></table></div>\n",
       "<h3><span style=\"font-family: monospace\">inner</span></h3><div><style  type=\"text/css\" >\n",
       "    #T_ded1de4b_ad03_11ec_840a_645d86784bd2 th {\n",
       "          text-align: left;\n",
       "    }    #T_ded1de4b_ad03_11ec_840a_645d86784bd2row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 66.0%, transparent 66.0%);\n",
       "        }    #T_ded1de4b_ad03_11ec_840a_645d86784bd2row0_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 99.0%, transparent 99.0%);\n",
       "        }    #T_ded1de4b_ad03_11ec_840a_645d86784bd2row0_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_ded1de4b_ad03_11ec_840a_645d86784bd2row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 99.0%, transparent 99.0%);\n",
       "        }    #T_ded1de4b_ad03_11ec_840a_645d86784bd2row1_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 99.0%, transparent 99.0%);\n",
       "        }    #T_ded1de4b_ad03_11ec_840a_645d86784bd2row1_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }</style><table id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >active_bytes</th>        <th class=\"col_heading level0 col1\" >reserved_bytes</th>        <th class=\"col_heading level0 col2\" >line</th>        <th class=\"col_heading level0 col3\" >code</th>    </tr>    <tr>        <th class=\"col_heading level1 col0\" >all</th>        <th class=\"col_heading level1 col1\" >all</th>        <th class=\"col_heading level1 col2\" ></th>        <th class=\"col_heading level1 col3\" ></th>    </tr>    <tr>        <th class=\"col_heading level2 col0\" >peak</th>        <th class=\"col_heading level2 col1\" >peak</th>        <th class=\"col_heading level2 col2\" ></th>        <th class=\"col_heading level2 col3\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row0_col0\" class=\"data row0 col0\" >80.00K</td>\n",
       "                        <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row0_col1\" class=\"data row0 col1\" >2.00M</td>\n",
       "                        <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "                        <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row0_col3\" class=\"data row0 col3\" >def inner():\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row1_col0\" class=\"data row1 col0\" >120.00K</td>\n",
       "                        <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row1_col1\" class=\"data row1 col1\" >2.00M</td>\n",
       "                        <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "                        <td id=\"T_ded1de4b_ad03_11ec_840a_645d86784bd2row1_col3\" class=\"data row1 col3\" >    torch.nn.Linear(100, 100).cuda()\n",
       "</td>\n",
       "            </tr>\n",
       "    </tbody></table></div>"
      ],
      "text/plain": [
       "## outer\n",
       "\n",
       "active_bytes reserved_bytes line  code                                           \n",
       "         all            all                                                      \n",
       "        peak           peak                                                      \n",
       "       0.00B          0.00B    4  def outer():                                   \n",
       "      40.00K          2.00M    5      linear = torch.nn.Linear(100, 100).cuda()  \n",
       "      80.00K          2.00M    6      linear2 = torch.nn.Linear(100, 100).cuda() \n",
       "     120.00K          2.00M    7      inner()                                    \n",
       "\n",
       "\n",
       "## inner\n",
       "\n",
       "active_bytes reserved_bytes line  code                                 \n",
       "         all            all                                            \n",
       "        peak           peak                                            \n",
       "      80.00K          2.00M    1  def inner():                         \n",
       "     120.00K          2.00M    2      torch.nn.Linear(100, 100).cuda() "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner():\n",
    "    torch.nn.Linear(100, 100).cuda()\n",
    "\n",
    "def outer():\n",
    "    linear = torch.nn.Linear(100, 100).cuda()\n",
    "    linear2 = torch.nn.Linear(100, 100).cuda()\n",
    "    inner()\n",
    "\n",
    "with LineProfiler(outer, inner) as prof:\n",
    "    outer()\n",
    "prof.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to profile BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=10).cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    device = torch.device('cuda:0')\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "    data = tokenizer(['This is a sentence'], return_tensors='pt').to(device)\n",
    "    labels = torch.Tensor([1] * len(data.input_ids[0])).to(dtype=torch.long).cuda()\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    model = initialize_model()\n",
    "    data, labels = get_data()\n",
    "    loss, logits = model(data.input_ids, token_type_ids=None, attention_mask=data.attention_mask, labels=labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3><span style=\"font-family: monospace\">run_model</span></h3><div><style  type=\"text/css\" >\n",
       "    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2 th {\n",
       "          text-align: left;\n",
       "    }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row0_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row0_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row1_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row1_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row2_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row2_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row2_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row3_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 99.0%, transparent 99.0%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row3_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 99.0%, transparent 99.0%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row3_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row4_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 99.0%, transparent 99.0%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row4_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 99.0%, transparent 99.0%);\n",
       "        }    #T_e1e54a2c_ad03_11ec_840a_645d86784bd2row4_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }</style><table id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >active_bytes</th>        <th class=\"col_heading level0 col1\" >reserved_bytes</th>        <th class=\"col_heading level0 col2\" >line</th>        <th class=\"col_heading level0 col3\" >code</th>    </tr>    <tr>        <th class=\"col_heading level1 col0\" >all</th>        <th class=\"col_heading level1 col1\" >all</th>        <th class=\"col_heading level1 col2\" ></th>        <th class=\"col_heading level1 col3\" ></th>    </tr>    <tr>        <th class=\"col_heading level2 col0\" >peak</th>        <th class=\"col_heading level2 col1\" >peak</th>        <th class=\"col_heading level2 col2\" ></th>        <th class=\"col_heading level2 col3\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row0_col0\" class=\"data row0 col0\" >0.00B</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row0_col1\" class=\"data row0 col1\" >0.00B</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row0_col3\" class=\"data row0 col3\" >def run_model():\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row1_col0\" class=\"data row1 col0\" >413.70M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row1_col1\" class=\"data row1 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row1_col3\" class=\"data row1 col3\" >    model = initialize_model()\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row2_col0\" class=\"data row2 col0\" >413.71M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row2_col1\" class=\"data row2 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row2_col3\" class=\"data row2 col3\" >    data, labels = get_data()\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row3_col0\" class=\"data row3 col0\" >417.21M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row3_col1\" class=\"data row3 col1\" >472.00M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row3_col2\" class=\"data row3 col2\" >4</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row3_col3\" class=\"data row3 col3\" >    loss, logits = model(data.input_ids, token_type_ids=None, attention_mask=data.attention_mask, labels=labels)\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row4_col0\" class=\"data row4 col0\" >417.19M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row4_col1\" class=\"data row4 col1\" >472.00M</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row4_col2\" class=\"data row4 col2\" >5</td>\n",
       "                        <td id=\"T_e1e54a2c_ad03_11ec_840a_645d86784bd2row4_col3\" class=\"data row4 col3\" >    return loss\n",
       "</td>\n",
       "            </tr>\n",
       "    </tbody></table></div>\n",
       "<h3><span style=\"font-family: monospace\">initialize_model</span></h3><div><style  type=\"text/css\" >\n",
       "    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2 th {\n",
       "          text-align: left;\n",
       "    }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row0_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row0_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row1_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row1_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row2_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row2_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2d_ad03_11ec_840a_645d86784bd2row2_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }</style><table id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >active_bytes</th>        <th class=\"col_heading level0 col1\" >reserved_bytes</th>        <th class=\"col_heading level0 col2\" >line</th>        <th class=\"col_heading level0 col3\" >code</th>    </tr>    <tr>        <th class=\"col_heading level1 col0\" >all</th>        <th class=\"col_heading level1 col1\" >all</th>        <th class=\"col_heading level1 col2\" ></th>        <th class=\"col_heading level1 col3\" ></th>    </tr>    <tr>        <th class=\"col_heading level2 col0\" >peak</th>        <th class=\"col_heading level2 col1\" >peak</th>        <th class=\"col_heading level2 col2\" ></th>        <th class=\"col_heading level2 col3\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row0_col0\" class=\"data row0 col0\" >0.00B</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row0_col1\" class=\"data row0 col1\" >0.00B</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row0_col3\" class=\"data row0 col3\" >def initialize_model():\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row1_col0\" class=\"data row1 col0\" >413.70M</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row1_col1\" class=\"data row1 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row1_col3\" class=\"data row1 col3\" >    model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=10).cuda()\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row2_col0\" class=\"data row2 col0\" >413.70M</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row2_col1\" class=\"data row2 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "                        <td id=\"T_e1e54a2d_ad03_11ec_840a_645d86784bd2row2_col3\" class=\"data row2 col3\" >    return model\n",
       "</td>\n",
       "            </tr>\n",
       "    </tbody></table></div>\n",
       "<h3><span style=\"font-family: monospace\">get_data</span></h3><div><style  type=\"text/css\" >\n",
       "    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2 th {\n",
       "          text-align: left;\n",
       "    }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row0_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row0_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row0_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row1_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row1_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row1_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row2_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row2_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row2_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row3_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row3_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row3_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row4_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row4_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row4_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row5_col0 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#4878d0 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row5_col1 {\n",
       "            width:  10em;\n",
       "             height:  80%;\n",
       "            background:  linear-gradient(90deg,#ee854a 98.2%, transparent 98.2%);\n",
       "        }    #T_e1e54a2e_ad03_11ec_840a_645d86784bd2row5_col3 {\n",
       "            text-align:  left;\n",
       "            white-space:  pre;\n",
       "            font-family:  monospace;\n",
       "        }</style><table id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >active_bytes</th>        <th class=\"col_heading level0 col1\" >reserved_bytes</th>        <th class=\"col_heading level0 col2\" >line</th>        <th class=\"col_heading level0 col3\" >code</th>    </tr>    <tr>        <th class=\"col_heading level1 col0\" >all</th>        <th class=\"col_heading level1 col1\" >all</th>        <th class=\"col_heading level1 col2\" ></th>        <th class=\"col_heading level1 col3\" ></th>    </tr>    <tr>        <th class=\"col_heading level2 col0\" >peak</th>        <th class=\"col_heading level2 col1\" >peak</th>        <th class=\"col_heading level2 col2\" ></th>        <th class=\"col_heading level2 col3\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row0_col0\" class=\"data row0 col0\" >413.70M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row0_col1\" class=\"data row0 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row0_col2\" class=\"data row0 col2\" >1</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row0_col3\" class=\"data row0 col3\" >def get_data():\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row1_col0\" class=\"data row1 col0\" >413.70M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row1_col1\" class=\"data row1 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row1_col2\" class=\"data row1 col2\" >2</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row1_col3\" class=\"data row1 col3\" >    device = torch.device('cuda:0')\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row2_col0\" class=\"data row2 col0\" >413.70M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row2_col1\" class=\"data row2 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row2_col2\" class=\"data row2 col2\" >3</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row2_col3\" class=\"data row2 col3\" >    tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row3_col0\" class=\"data row3 col0\" >413.71M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row3_col1\" class=\"data row3 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row3_col2\" class=\"data row3 col2\" >4</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row3_col3\" class=\"data row3 col3\" >    data = tokenizer(['This is a sentence'], return_tensors='pt').to(device)\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row4_col0\" class=\"data row4 col0\" >413.71M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row4_col1\" class=\"data row4 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row4_col2\" class=\"data row4 col2\" >5</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row4_col3\" class=\"data row4 col3\" >    labels = torch.Tensor([1] * len(data.input_ids[0])).to(dtype=torch.long).cuda()\n",
       "</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row5_col0\" class=\"data row5 col0\" >413.71M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row5_col1\" class=\"data row5 col1\" >468.00M</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row5_col2\" class=\"data row5 col2\" >6</td>\n",
       "                        <td id=\"T_e1e54a2e_ad03_11ec_840a_645d86784bd2row5_col3\" class=\"data row5 col3\" >    return data, labels\n",
       "</td>\n",
       "            </tr>\n",
       "    </tbody></table></div>"
      ],
      "text/plain": [
       "## run_model\n",
       "\n",
       "active_bytes reserved_bytes line code                                                                                                             \n",
       "         all            all                                                                                                                       \n",
       "        peak           peak                                                                                                                       \n",
       "       0.00B          0.00B    1  def run_model():                              ...                                                               \n",
       "     413.70M        468.00M    2      model = initialize_model()                ...                                                               \n",
       "     413.71M        468.00M    3      data, labels = get_data()                 ...                                                               \n",
       "     417.21M        472.00M    4      loss, logits = model(data.input_ids, token...                                                               \n",
       "     417.19M        472.00M    5      return loss                               ...                                                               \n",
       "\n",
       "\n",
       "## initialize_model\n",
       "\n",
       "active_bytes reserved_bytes line code                                                                                            \n",
       "         all            all                                                                                                      \n",
       "        peak           peak                                                                                                      \n",
       "       0.00B          0.00B    1  def initialize_model():                       ...                                              \n",
       "     413.70M        468.00M    2      model = BertForTokenClassification.from_pr...                                              \n",
       "     413.70M        468.00M    3      return model                              ...                                              \n",
       "\n",
       "\n",
       "## get_data\n",
       "\n",
       "active_bytes reserved_bytes line code                                                                                \n",
       "         all            all                                                                                          \n",
       "        peak           peak                                                                                          \n",
       "     413.70M        468.00M    1  def get_data():                               ...                                  \n",
       "     413.70M        468.00M    2      device = torch.device('cuda:0')           ...                                  \n",
       "     413.70M        468.00M    3      tokenizer = BertTokenizerFast.from_pretrai...                                  \n",
       "     413.71M        468.00M    4      data = tokenizer(['This is a sentence'], r...                                  \n",
       "     413.71M        468.00M    5      labels = torch.Tensor([1] * len(data.input...                                  \n",
       "     413.71M        468.00M    6      return data, labels                       ...                                  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with LineProfiler(run_model, initialize_model, get_data) as prof:\n",
    "    run_model()\n",
    "prof.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very much useful data. Let's try to look at the BERT forward function..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT forward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing ProfiledBertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing ProfiledBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ProfiledBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ProfiledBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## BertForTokenClassification.forward\n",
      "\n",
      "active_bytes reserved_bytes  line code                                                                                                  \n",
      "         all            all                                                                                                             \n",
      "        peak           peak                                                                                                             \n",
      "     413.71M        468.00M  1463      @add_start_docstrings_to_callable(BERT_INP...                                                    \n",
      "                             1464      @add_code_sample_docstrings(              ...                                                    \n",
      "                             1465          tokenizer_class=_TOKENIZER_FOR_DOC,   ...                                                    \n",
      "                             1466          checkpoint=\"bert-base-uncased\",       ...                                                    \n",
      "                             1467          output_type=TokenClassifierOutput,    ...                                                    \n",
      "                             1468          config_class=_CONFIG_FOR_DOC,         ...                                                    \n",
      "                             1469      )                                         ...                                                    \n",
      "                             1470      def forward(                              ...                                                    \n",
      "                             1471          self,                                 ...                                                    \n",
      "                             1472          input_ids=None,                       ...                                                    \n",
      "                             1473          attention_mask=None,                  ...                                                    \n",
      "                             1474          token_type_ids=None,                  ...                                                    \n",
      "                             1475          position_ids=None,                    ...                                                    \n",
      "                             1476          head_mask=None,                       ...                                                    \n",
      "                             1477          inputs_embeds=None,                   ...                                                    \n",
      "                             1478          labels=None,                          ...                                                    \n",
      "                             1479          output_attentions=None,               ...                                                    \n",
      "                             1480          output_hidden_states=None,            ...                                                    \n",
      "                             1481          return_dict=None,                     ...                                                    \n",
      "                             1482      ):                                        ...                                                    \n",
      "                             1483          r\"\"\"                                  ...                                                    \n",
      "                             1484          labels (:obj:`torch.LongTensor` of sha...                                                    \n",
      "                             1485              Labels for computing the token cla...                                                    \n",
      "                             1486              Indices should be in ``[0, ..., co...                                                    \n",
      "                             1487          \"\"\"                                   ...                                                    \n",
      "     413.71M        468.00M  1488          return_dict = return_dict if return_di...                                                    \n",
      "                             1489                                                ...                                                    \n",
      "     413.71M        468.00M  1490          outputs = self.bert(                  ...                                                    \n",
      "     413.71M        468.00M  1491              input_ids,                        ...                                                    \n",
      "     413.71M        468.00M  1492              attention_mask=attention_mask,    ...                                                    \n",
      "     413.71M        468.00M  1493              token_type_ids=token_type_ids,    ...                                                    \n",
      "     413.71M        468.00M  1494              position_ids=position_ids,        ...                                                    \n",
      "     413.71M        468.00M  1495              head_mask=head_mask,              ...                                                    \n",
      "     413.71M        468.00M  1496              inputs_embeds=inputs_embeds,      ...                                                    \n",
      "     413.71M        468.00M  1497              output_attentions=output_attention...                                                    \n",
      "     413.71M        468.00M  1498              output_hidden_states=output_hidden...                                                    \n",
      "     417.21M        472.00M  1499              return_dict=return_dict,          ...                                                    \n",
      "                             1500          )                                     ...                                                    \n",
      "                             1501                                                ...                                                    \n",
      "     417.19M        472.00M  1502          sequence_output = outputs[0]          ...                                                    \n",
      "                             1503                                                ...                                                    \n",
      "     417.19M        472.00M  1504          sequence_output = self.dropout(sequenc...                                                    \n",
      "     417.19M        472.00M  1505          logits = self.classifier(sequence_outp...                                                    \n",
      "                             1506                                                ...                                                    \n",
      "     417.19M        472.00M  1507          loss = None                           ...                                                    \n",
      "     417.19M        472.00M  1508          if labels is not None:                ...                                                    \n",
      "     417.19M        472.00M  1509              loss_fct = CrossEntropyLoss()     ...                                                    \n",
      "                             1510              # Only keep active parts of the lo...                                                    \n",
      "     417.19M        472.00M  1511              if attention_mask is not None:    ...                                                    \n",
      "     417.19M        472.00M  1512                  active_loss = attention_mask.v...                                                    \n",
      "     417.19M        472.00M  1513                  active_logits = logits.view(-1...                                                    \n",
      "     417.19M        472.00M  1514                  active_labels = torch.where(  ...                                                    \n",
      "     417.19M        472.00M  1515                      active_loss, labels.view(-...                                                    \n",
      "                             1516                  )                             ...                                                    \n",
      "     417.19M        472.00M  1517                  loss = loss_fct(active_logits,...                                                    \n",
      "                             1518              else:                             ...                                                    \n",
      "                             1519                  loss = loss_fct(logits.view(-1...                                                    \n",
      "                             1520                                                ...                                                    \n",
      "     417.19M        472.00M  1521          if not return_dict:                   ...                                                    \n",
      "     417.19M        472.00M  1522              output = (logits,) + outputs[2:]  ...                                                    \n",
      "     417.19M        472.00M  1523              return ((loss,) + output) if loss ...                                                    \n",
      "                             1524                                                ...                                                    \n",
      "                             1525          return TokenClassifierOutput(         ...                                                    \n",
      "                             1526              loss=loss,                        ...                                                    \n",
      "                             1527              logits=logits,                    ...                                                    \n",
      "                             1528              hidden_states=outputs.hidden_state...                                                    \n",
      "                             1529              attentions=outputs.attentions,    ...                                                    \n",
      "                             1530          )                                     ...                                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_memlab import LineProfiler, MemReporter, profile\n",
    "from transformers import BertForTokenClassification, BertTokenizerFast\n",
    "\n",
    "class ProfiledBertForTokenClassification(BertForTokenClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        with LineProfiler(super().forward) as prof:\n",
    "            result = super().forward(*args, **kwargs)\n",
    "        # jupyter display stops working here, so I had to print stats\n",
    "        print(prof.display())\n",
    "        return result\n",
    "\n",
    "model = ProfiledBertForTokenClassification.from_pretrained('bert-base-cased', num_labels=10).cuda()\n",
    "device = torch.device('cuda:0')\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "data = tokenizer(['This is a sentence'], return_tensors='pt').to(device)\n",
    "labels = torch.Tensor([1] * len(data.input_ids[0])).to(dtype=torch.long).cuda()\n",
    "loss, logits = model(data.input_ids, token_type_ids=None, attention_mask=data.attention_mask, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, to get deeper - in self.bert layers, for example - we'll need to wrap self.bert call (line 1490) in LineProfiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
